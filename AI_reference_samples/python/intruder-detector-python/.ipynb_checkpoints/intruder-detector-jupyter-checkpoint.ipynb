{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intruder Detector\n",
    "\n",
    "This application is one of a series of IoT reference implementations illustrating how to develop a working solution for a problem. The reference implementation demonstrates how to create a smart video IoT solution using Intel® hardware and software tools. This solution detects any number of objects in a designated area, providing the number of objects in the frame and total count.\n",
    "\n",
    "## Overview of how it works\n",
    "At start-up the sample application reads the equivalent of command line arguments and loads a network and image from the video input to the Inference Engine (IE) plugin. A job is submitted to an edge compute node with a hardware accelerator such as Intel® HD Graphics GPU, Intel® Movidius™ Neural Compute Stick 2 and and Intel® Arria® 10 FPGA.\n",
    "After the inference is completed, the output videos are appropriately stored in the /results/[device] directory, which can then be viewed within the Jupyter Notebook instance.\n",
    "\n",
    "## Demonstration objectives\n",
    "* Video as input is supported using **OpenCV**\n",
    "* Inference performed on edge hardware (rather than on the development node hosting this Jupyter notebook)\n",
    "* **OpenCV** provides the bounding boxes, labels and other information\n",
    "* Visualization of the resulting bounding boxes\n",
    "\n",
    "\n",
    "## Step 0: Set Up\n",
    "\n",
    "### 0.1: Import dependencies\n",
    "\n",
    "Run the below cell to import Python dependencies needed for displaying the results in this notebook\n",
    "(tip: select the cell and use **Ctrl+enter** to run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2  (Optional-step): Original video without inference\n",
    "\n",
    "If you are curious to see the input video, run the following cell to view the original video stream used for inference and Intruder detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Intruder Video</h2>\n",
       "    \n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"person-bicycle-car-detection.mp4 \" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ln -sf ./resources/person-bicycle-car-detection.mp4 \n",
    "videoHTML('Intruder Video', ['person-bicycle-car-detection.mp4 '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 0.3 The Labels File\n",
    "\n",
    "In order to work, this application requires a labels file associated with the model being used for detection.\n",
    "\n",
    "The labels file is a text file containing all the classes/labels that the model can recognize, in the order that it was trained to recognize them (one class per line).\n",
    "\n",
    "For the **person-vehicle-bike-detection-crossroad-0078** model, find the class file labels.txt in the resources folder.\n",
    "\n",
    "### 0.4 The Config File\n",
    "\n",
    "The resources/conf.txt contains the path to the video that will be used by the application, followed by the labels to be detected on video. All labels (intruders) defined will be detected on video.\n",
    "\n",
    "Each line of the conf.txt file is of the form ``video: <path/to/video>`` or ``intruder: <label>``.<br>\n",
    "The labels used in the conf.txt file must coincide with the labels from the labels file.\n",
    "\n",
    "Example of the conf.txt file:\n",
    "\n",
    "```\n",
    "video: videos/video1.mp4\n",
    "intruder: person\n",
    "intruder: dog\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Using Intel® Distribution of OpenVINO™ toolkit\n",
    "\n",
    "We will be using Intel® Distribution of OpenVINO™ toolkit Inference Engine (IE) to locate intruder in the frame.\n",
    "There are five steps involved in this task:\n",
    "\n",
    "1. Create an Intermediate Representation (IR) Model using the Model Optimizer by Intel\n",
    "2. Choose a device and create IEPlugin for the device\n",
    "3. Read the IRModel using IENetwork\n",
    "4. Load the IENetwork into the Plugin\n",
    "5. Run inference.\n",
    "\n",
    "### 1.1 Creating IR Model\n",
    "\n",
    "The Model Optimizer creates Intermediate Representation (IR) models that are optimized for different end-point target devices.\n",
    "These models can be created from existing DNN models from popular frameworks (e.g. Caffe*, TF) using the Model Optimizer. \n",
    "The Intel® Distribution of OpenVINO™ toolkit includes a utility script `model_downloader.py` that you can use to download some common models. Run the following cell to see the models available through `model_downloader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The '!' is a special Jupyter Notebook command that allows you to run shell commands as if you are in a command line. So the above command will work straight out of the box on in a terminal (with '!' removed).\n",
    "\n",
    "Some of these downloaded models are already in the IR format, while others will require the model optimizer. In this demo, we will be using the **person-vehicle-bike-detection-crossroad-0078** model, which is already in IR format. This model can be downloaded with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Security/object_detection/crossroad/0078/dldt/FP32/person-vehicle-bike-detection-crossroad-0078.xml\n",
      "... 100%, 165 KB, 231 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Security/object_detection/crossroad/0078/dldt/FP32/person-vehicle-bike-detection-crossroad-0078.bin\n",
      "... 100%, 4603 KB, 2877 KB/s, 1 seconds passed\n",
      "\n",
      "========= Downloading models/Security/object_detection/crossroad/0078/dldt/FP16/person-vehicle-bike-detection-crossroad-0078.xml\n",
      "... 100%, 165 KB, 1247 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Security/object_detection/crossroad/0078/dldt/FP16/person-vehicle-bike-detection-crossroad-0078.bin\n",
      "... 100%, 2301 KB, 3370 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Security/object_detection/crossroad/0078/dldt/INT8/person-vehicle-bike-detection-crossroad-0078.xml\n",
      "... 100%, 20364 KB, 3836 KB/s, 5 seconds passed\n",
      "\n",
      "========= Downloading models/Security/object_detection/crossroad/0078/dldt/INT8/person-vehicle-bike-detection-crossroad-0078.bin\n",
      "... 100%, 4603 KB, 3579 KB/s, 1 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "No matching topologies: \"person-vehicle-bike-detection-crossroad-0078-fp16\"\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name person-vehicle-bike-detection-crossroad-0078 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name person-vehicle-bike-detection-crossroad-0078-fp16 -o models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments are as follows:\n",
    "* --name : name of the model you want to download. It should be one of the models listed in the previous cell\n",
    "* -o : output directory. If this directory does not exist, it will be created for you.\n",
    "\n",
    "There are more arguments to this script and you can get the full list using the `-h` option.\n",
    "\n",
    "\n",
    "With the `-o` option set as above, this command downloads the model in the directory `models`, with the model files (.xml and .bin) located at `/Security/object_detection/crossroad/0078/dldt directory`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Inference on a video\n",
    "\n",
    "The inference code is already implemented in \n",
    "<a href=\"intruder-detector.py\">intruder-detector.py</a>.\n",
    "\n",
    "The Python code takes in command line arguments for model, label file etc.\n",
    "\n",
    "**Command line arguments options and how they are interpreted in the application source code**\n",
    "\n",
    "```\n",
    "python3 intruder-detector.py -m ${MODELPATH} \\\n",
    "                             -lb resources/labels.txt \\\n",
    "                             -o $OUTPUT_FILE \\\n",
    "                             -d $DEVICE \\\n",
    "                             -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "##### The description of the arguments used in the argument parser is the command line executable equivalent.\n",
    "* -m location of the pre-trained IR model which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware\n",
    "* -lb label file on which the model is trained\n",
    "* -o location where the output file with inference needs to be stored. (results/[device])\n",
    "* -d type of Hardware Acceleration (CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "* -l absolute path to the shared library and is currently optimized for core/xeon (/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating job file\n",
    " \n",
    "To run inference on the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:51:08 - Intruder person detected on Cam 1\n",
      "13:51:15 - Intruder car detected on Cam 1\n",
      "13:51:29 - Intruder person detected on Cam 1\n",
      "13:51:31 - Intruder car detected on Cam 1\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "#Running the intruder detector code\n",
    "!python3 intruder-detector.py -m models/Security/object_detection/crossroad/0078/dldt/FP32/person-vehicle-bike-detection-crossroad-0078.xml -lb resources/labels.txt -o \"results\" -d CPU -l /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension_avx2.so \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Wait!***\n",
    "\n",
    "Please wait for the inference jobs and video rendering complete before proceeding to the next step.\n",
    "\n",
    "## Step 3: View Results\n",
    "\n",
    "Once the jobs are completed, the queue system outputs the stdout and stderr streams of each job into files with names of the form\n",
    "\n",
    "`intrud_{type}.o{JobID}`\n",
    "\n",
    "`intrud_{type}.e{JobID}`\n",
    "\n",
    "(here, intrud_{type} corresponds to the `-N` option of qsub).\n",
    "\n",
    "However, for this case, we may be more interested in the output video files. They are stored in mp4 format inside the `results/[device]` directory.\n",
    "We wrote a short utility script that will display these videos with in the notebook.\n",
    "Run the cells below to display them.\n",
    "See `demoutils.py` if you are interested in understanding further how the results are displayed in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Intel Core CPU)</h2>\n",
       "    <p>647 \n",
       " frames processed in 30 \n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"240\"><source src=\"results/video1.mp4\" type=\"video/mp4\" /></video><video alt=\"\" controls autoplay height=\"240\"><source src=\"results/Statistics.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('Intel Core CPU)', \n",
    "          ['results/video1.mp4','results/Statistics.mp4'],'results/stats.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
