{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Aisle Monitor\n",
    "\n",
    "This reference implementation counts the number of people present in an image. It takes the input from a video file for processing. Snapshots of the output are taken at regular intervals and are uploaded to the cloud. It also stores the snapshots of the output locally.\n",
    "\n",
    "## Overview of how it works\n",
    "At start-up the sample application reads the equivalent of command line arguments and loads a network and image from the video input to the Inference Engine (IE) plugin. A job is submitted to an edge compute node with a hardware accelerator such as Intel® HD Graphics GPU, Intel® Movidius™ Neural Compute Stick 2 and Intel® Arria® 10 FPGA.\n",
    "After the inference is completed, the output videos are appropriately stored in the /results/[device] directory, which can then be viewed within the Jupyter Notebook instance.\n",
    "\n",
    "## Demonstration objectives\n",
    "* Video as input is supported using **OpenCV**\n",
    "* Inference performed on edge hardware (rather than on the development node hosting this Jupyter notebook)\n",
    "* **OpenCV** provides the bounding boxes, labels and other information\n",
    "* Visualization of the resulting bounding boxes\n",
    "\n",
    "\n",
    "## Step 0: Set Up\n",
    "\n",
    "### 0.1: Import dependencies\n",
    "\n",
    "Run the below cell to import Python dependencies needed for displaying the results in this notebook\n",
    "(tip: select the cell and use **Ctrl+enter** to run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2  (Optional-step): Original video without inference\n",
    "\n",
    "If you are curious to see the input video, run the following cell to view the original video stream used for inference and store aisle monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Store Aisle Video</h2>\n",
       "    \n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"store-aisle-detection.mp4 \" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ln -sf ./resources/store-aisle-detection.mp4\n",
    "videoHTML('Store Aisle Video', ['store-aisle-detection.mp4 '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Install Azure\n",
    "To run application on azure cloud `azure` should be installed in the system. Run following commands to install azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Azure\n",
      "Collecting azure\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/5e/f94bd8091ab0ccc68ee902e188d4e8cd3b38dc77155a1c187cbf4767d0e4/azure-4.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-storage-queue~=1.3 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/72/94/4db044f1c155b40c5ebc037bfd9d1c24562845692c06798fbe869fe160e6/azure_storage_queue-1.4.0-py2.py3-none-any.whl\n",
      "Collecting azure-servicefabric~=6.3.0.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/2c/d9/3e33ad19eb57988dff3aac06bab241736f86dc692a38c5ff6bb6fb959243/azure_servicefabric-6.3.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-batch~=4.1 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/b1/fa/1053b5dcd88e5de8e8cd70a4d7189ffad037542963ea86b518deb612c498/azure_batch-4.1.3-py2.py3-none-any.whl\n",
      "Collecting azure-eventgrid~=1.1 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/01/e4/2a3319f04c69f0113a05884664769d462dcec55031c6d154a2c4176cfb79/azure_eventgrid-1.3.0-py2.py3-none-any.whl\n",
      "Collecting azure-cosmosdb-table~=1.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/55/81/f57fea1cdab4490bc185e48a4db2451795fde37eb8fed1808e7e8fd2c99e/azure_cosmosdb_table-1.0.5-py2.py3-none-any.whl\n",
      "Collecting azure-applicationinsights~=0.1.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/3b/f7/3af9ce8a9a597998629436889cf5d69d1a0c96713e795fd372e4af785635/azure_applicationinsights-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-storage-blob~=1.3 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/25/f4/a307ed89014e9abb5c5cfc8ca7f8f797d12f619f17a6059a6fd4b153b5d0/azure_storage_blob-1.5.0-py2.py3-none-any.whl\n",
      "Collecting azure-servicemanagement-legacy~=0.20.6 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/2b/0813d459df7ec04bb8c6a250882ee88b672a5f8d16a237978c89436a053e/azure_servicemanagement_legacy-0.20.6-py2.py3-none-any.whl\n",
      "Collecting azure-servicebus~=0.21.1 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/de/47c0df32b57512ac9640ba239c7eeca22cb908bd8b645235729ec4f37196/azure_servicebus-0.21.1-py2.py3-none-any.whl\n",
      "Collecting azure-keyvault~=1.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/80/37/e80f577570b32648c4b88c8c48a46501a4868ae4c8d905774fd02c2b01fc/azure_keyvault-1.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-loganalytics~=0.1.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/54/e2/1d30270441a50efce1d52eb426710fc98269eb8bdac44ee966bbd07846da/azure_loganalytics-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-datalake-store~=0.0.18 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/8e/7f990443bd3d3b6a9112ff8d15d93216e67378a037ec9090d7dd248eec2d/azure_datalake_store-0.0.47-py2.py3-none-any.whl\n",
      "Collecting azure-graphrbac~=0.40.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/0a/29f7e2914033e2536026b8f0d7f8deb1edda68c9a93ce4757b2b1e39568b/azure_graphrbac-0.40.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt~=4.0 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/8e/6fa401c437579127e726487582a9861fef09022c4ab50901bb499a8e4fc1/azure_mgmt-4.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-storage-file~=1.3 (from azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/33/6c611563412ffc409b2413ac50e3a063133ea235b86c137759774c77f3ad/azure_storage_file-1.4.0-py2.py3-none-any.whl\n",
      "Collecting azure-common>=1.1.5 (from azure-storage-queue~=1.3->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/00/55/a703923c12cd3172d5c007beda0c1a34342a17a6a72779f8a7c269af0cd6/azure_common-1.1.23-py2.py3-none-any.whl\n",
      "Collecting azure-storage-common~=1.4 (from azure-storage-queue~=1.3->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/6c/b2285bf3687768dbf61b6bc085b0c1be2893b6e2757a9d023263764177f3/azure_storage_common-1.4.2-py2.py3-none-any.whl\n",
      "Collecting azure-nspkg>=2.0.0 (from azure-servicefabric~=6.3.0.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting msrest<2.0.0,>=0.4.26 (from azure-servicefabric~=6.3.0.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/b0/c34b3ea9b2ed74b800520fbefb312cdb7f05c20b8bd42e5e7662a5614f98/msrest-0.6.10-py2.py3-none-any.whl\n",
      "Collecting msrestazure<2.0.0,>=0.4.20 (from azure-batch~=4.1->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/68/75/5cb56ca8cbc6c5fe476e4878c73f57a331edcf55e5d3fcb4a7377d7d659d/msrestazure-0.6.2-py2.py3-none-any.whl\n",
      "Collecting azure-cosmosdb-nspkg>=2.0.0 (from azure-cosmosdb-table~=1.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/58/0d/1329b47e5386b0acf4e42ada2284851eff60ef3337a87e5b2dfedabbfcb1/azure_cosmosdb_nspkg-2.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.5/dist-packages (from azure-cosmosdb-table~=1.0->azure) (2.20.1)\n",
      "Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from azure-cosmosdb-table~=1.0->azure) (1.2.3)\n",
      "Requirement already satisfied: python-dateutil in /home/ojuan/.local/lib/python3.5/site-packages (from azure-cosmosdb-table~=1.0->azure) (2.8.0)\n",
      "Collecting cffi (from azure-datalake-store~=0.0.18->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/76/135eeffe0089e6724bdd65c1bf9f1654db9b47783e65b8d9f1454c540d8b/cffi-1.12.3-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting adal>=0.4.2 (from azure-datalake-store~=0.0.18->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/4f/b5/3ea9ae3d1096b9ff31e8f1846c47d49f3129a12464ac0a73b602de458298/adal-1.2.2-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-maps~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/e4/04/c64326729e842f3eab1fd527f7582e269e4b0e5b9324a4562edaf0371953/azure_mgmt_maps-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-notificationhubs~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/55/c0/62a0495583dfc44830f711be52cb4a4e116c2f72c89a19b90d654bdafc4a/azure_mgmt_notificationhubs-2.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-compute~=4.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/4d/7ac30585c567a8b9fe8294e0e956c6ef48665522ddf8f8c44bf38b700798/azure_mgmt_compute-4.6.2-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-iothubprovisioningservices~=0.2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/84/ce/3500c731a5c5b31028e662aa41bc45f75301834a0c03adeacfe7ef7bd86e/azure_mgmt_iothubprovisioningservices-0.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-containerregistry~=2.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/97/70/8c2d0509db466678eba16fa2b0a539499f3b351b1f2993126ad843d5be13/azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-managementgroups~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/f2/50/591adac2a6cd8d77cccd38bdf5d177ad6a2e95b9217daa9a60b5d86de5cd/azure_mgmt_managementgroups-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-dns~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c7/d7/0f986a64b06db93cf29b76f9a188f5778eb959624a00ed6aedc335ee58d2/azure_mgmt_dns-2.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-marketplaceordering~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/a8/cb/13502fdbaf520d08fb280eb31ecfe5d926b9cf92259c22280bbde96b307d/azure_mgmt_marketplaceordering-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-recoveryservicesbackup~=0.3.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/af/13b10d76bc0ff9188c9e5cd9f2726a5745029b76125938491f9abac5399d/azure_mgmt_recoveryservicesbackup-0.3.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-web~=0.35.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/21/04/3f2622720664c972d927fd9e58c0066e998739b7891649207765be674126/azure_mgmt_web-0.35.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-media~=1.0.0rc2 (from azure-mgmt~=4.0->azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://files.pythonhosted.org/packages/65/2e/6d9649bd5645ac32a179adfea5707f640fc51a57e493c27f0ab575789e85/azure_mgmt_media-1.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-redis~=5.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/a7/42342a984b2916972c5c5e24df94e3cd5e4377a8dc465a83415706d9be6f/azure_mgmt_redis-5.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-advisor~=1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/cb/f3/a86ba3e0784d12c8fe5cbf1f24e1b9255575a2f0892e08c46cddd0795dfd/azure_mgmt_advisor-1.0.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-msi~=0.2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/95/b451721e38ca0feddce03ee3ce86158e208d0150253bd371207a8df4e9c5/azure_mgmt_msi-0.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-servicebus~=0.5.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/ad/9e90f8bab40a9682410e57ed08a799be113c5e470bec247b099038c6389e/azure_mgmt_servicebus-0.5.3-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-datalake-analytics~=0.6.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/e7/5d909ef5812fc31f2871f3510ef43af93157ba51be03b6f798afba7a29d8/azure_mgmt_datalake_analytics-0.6.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-devtestlabs~=2.2 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/93/a64abaede2fc6a52476af8ceab9cedb368c49e948d9385cbe7cd4ce5ffff/azure_mgmt_devtestlabs-2.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-resource~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/1b/2d/9c3f2c9bf6e19f3efe4ddcaa946ea515d5229f4c0b387e224267e77fb73b/azure_mgmt_resource-2.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-powerbiembedded~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/64/2b/5a69d118626a83055ce577fb6ba35c114e72f0273d0c4d943b909ee8d51e/azure_mgmt_powerbiembedded-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-machinelearningcompute~=0.4.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/9c/f8eb81b307df4465809b182f2fe44c288eeb41c0ab54f91b61ac554998a9/azure_mgmt_machinelearningcompute-0.4.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-keyvault~=1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-devspaces~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/d3/ff9c39578f24fb4bd158a882788c7795b177cf3f23ce7cf1d8b52066a64e/azure_mgmt_devspaces-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-containerservice~=4.2 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/2f/0eba2dbd5d3f66c076a66b0020ccfe9c7e78534ac132afaa104c138680c1/azure_mgmt_containerservice-4.4.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-storage~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/5b/15e6a8109af53e4c2228142ea816532036700757d035fc1b9cd0f6a63b02/azure_mgmt_storage-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-scheduler~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/55/f3490698ff622244438e667e0321808e84389e69c5fb77a1d6db869d9bb7/azure_mgmt_scheduler-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-commerce~=1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/13/f421e77dd1fe3c9657a890f9c085f433fe422f54003ee03e631a8be5c4e7/azure_mgmt_commerce-1.0.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-iothub~=0.5.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/d6/b422df467b3d7f4e2975b590fbf6e12aaae0a497c7d080b4955a6a6d794a/azure_mgmt_iothub-0.5.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-reservations~=0.2.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/a9/2b/e0edb8dbe85e447005cde508b869e564f58270f631219f036d8ab71184f9/azure_mgmt_reservations-0.2.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-applicationinsights~=0.1.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/30/61/1d95a5ef3a9119a0d375d8670129375515de20e20409612e9671c99bd19f/azure_mgmt_applicationinsights-0.1.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-billing~=0.2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/24/5106287ea0f6562d965afb055e3c6c0da058f7844a70464e67bab56c6c4b/azure_mgmt_billing-0.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-subscription~=0.2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/72/f63f72d9c27659f96aae287f7ba67c9ba2877213c2c10d8b797e0dee5059/azure_mgmt_subscription-0.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-rdbms~=1.2 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/94/c850c8257d19b08eb6b03154d6fe21938801562b4082d27985f54ebe9de4/azure_mgmt_rdbms-1.9.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-loganalytics~=0.2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/40/c9b77bf82916e963aa701fb396673f7ddc4cdab95524b6d2edf927b05630/azure_mgmt_loganalytics-0.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-datamigration~=1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/8b/4f/7b149487e77d94e701288e1d0b066a7d522bdfe8595e992b5d39dfb00f80/azure_mgmt_datamigration-1.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-search~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/18/fa4e0d541332c0ba6ef16beaa9b55f831436949e7d0981d5677dff2ddfb5/azure_mgmt_search-2.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-batchai~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/a5/ab796c2a490155c14f9ac4240724ca5c56723315d4dc753030712e6f2e80/azure_mgmt_batchai-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-trafficmanager~=0.50.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/ed/4f/c322d72dc92dde543471bc23f9ac0eb6b9d0dc2441bb5ce938250040e307/azure_mgmt_trafficmanager-0.50.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-datalake-store~=0.5.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/ac/5685cd06dc8b245bb6b894815764a14bd62245ba4579b45148682f510fdd/azure_mgmt_datalake_store-0.5.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-iotcentral~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/58/4e/e2e5f2d545a46ada3705c85c45c12882a443d40f60e1a908c78058e15cf2/azure_mgmt_iotcentral-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-managementpartner~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/91/2bccd2bdca4158a7b6169538b25e22e0b4f8ff835754888aab45ffbd0448/azure_mgmt_managementpartner-0.1.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-hanaonazure~=0.1.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/f3/1b/50d300ae02158ab092f923132050b56c148f1b784c7b594d3275d4449769/azure_mgmt_hanaonazure-0.1.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-cdn~=3.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/97/bf/c41e8985b4ffaaad2baaded1fb7b113433ae2d30d65c1a8c226e72284b72/azure_mgmt_cdn-3.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-datafactory~=0.6.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/cf/01/32a6ad5ad348d965f7c106d819a1f6dc613f6aa98a720ffc529ef468016b/azure_mgmt_datafactory-0.6.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-cognitiveservices~=3.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/8d/c8/222ea2f533c6b8f8656f3091101b4c3aa32c162d2a609d07d1ae00172515/azure_mgmt_cognitiveservices-3.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-batch~=5.0 (from azure-mgmt~=4.0->azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://files.pythonhosted.org/packages/97/81/a9eb3fd2ab070159105b4cfe9640c24410ac8195286729d62bfdf871de94/azure_mgmt_batch-5.0.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-recoveryservices~=0.3.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/fd/7f/80327a27e03473101afb136e872279ad1386adf1bac14a58a9f839cd8352/azure_mgmt_recoveryservices-0.3.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-policyinsights~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/84/7021951ae69572a19af0ff9cca1d2abf3542d35af38796656ded1be08358/azure_mgmt_policyinsights-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-containerinstance~=1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/fd/d1/d770050f20ad81b80f7eb41f89e1a5d841cf74bf41c7e1ff137c46f28a1e/azure_mgmt_containerinstance-1.5.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-eventhub~=2.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/cb/3822bcfa815f894c86a27845ae4160c0169722598399234cd6f77bb82347/azure_mgmt_eventhub-2.6.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-servicefabric~=0.2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/06/fafe8b5d881cfa68927e61557c8419dcfacb93e07f4ab17cc60959707a53/azure_mgmt_servicefabric-0.2.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-network~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/95/d63833e95406626256893a2f3ef4e5029a168330e3a27817a9f5597c0e6f/azure_mgmt_network-2.7.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-logic~=3.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/98/693c515e97043520f5cebf1ecae7bf198df100f5f9870b53d4be3bcaa5ce/azure_mgmt_logic-3.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-eventgrid~=1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/54/5b/e91e616021ae9be0019c9c19cffb92b97d787246ca51cfcc0b0a0c6da77a/azure_mgmt_eventgrid-1.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-cosmosdb~=0.4.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/17/ed/d97a04c8c26e2432f2cf000b711daeb053e1cfbdb046bd5d070c941b4fcb/azure_mgmt_cosmosdb-0.4.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-relay~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/00/f7/f5c72bd19829cfaf9f070ec294c901ad7f98835ba9560fdad652afb1071f/azure_mgmt_relay-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-authorization~=0.50.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/17/55b974603c16be89c7a7c16bac57b7bce48527bf1bebc3f116f7215176e6/azure_mgmt_authorization-0.50.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-signalr~=0.1.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/10/32/379137548a4c6e4dfd15da6b1c476f2b1af52e8d7fe243fdac9ea2064427/azure_mgmt_signalr-0.1.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-monitor~=0.5.2 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/6a/3b/a8b95ee25f1c209ad82ad06de39f4efbfb9dc8a8dc5da5a7a48d7897bf3e/azure_mgmt_monitor-0.5.2-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-sql~=0.9.1 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/bb/219c76af961e9e6d1f5055d70c3cc06889b91375727a04367149c3aad640/azure_mgmt_sql-0.9.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-consumption~=2.0 (from azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/11/f4/2db9557494dfb17ff3edeae5726981143a7baace17df3712b189e343bd8c/azure_mgmt_consumption-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from msrest<2.0.0,>=0.4.26->azure-servicefabric~=6.3.0.0->azure) (2018.11.29)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest<2.0.0,>=0.4.26->azure-servicefabric~=6.3.0.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest<2.0.0,>=0.4.26->azure-servicefabric~=6.3.0.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests->azure-cosmosdb-table~=1.0->azure) (2.7)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests->azure-cosmosdb-table~=1.0->azure) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests->azure-cosmosdb-table~=1.0->azure) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ojuan/.local/lib/python3.5/site-packages (from python-dateutil->azure-cosmosdb-table~=1.0->azure) (1.12.0)\n",
      "Collecting pycparser (from cffi->azure-datalake-store~=0.0.18->azure)\n",
      "Requirement already satisfied: PyJWT>=1.0.0 in /usr/lib/python3/dist-packages (from adal>=0.4.2->azure-datalake-store~=0.0.18->azure) (1.3.0)\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-maps~=0.1.0->azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting azure-mgmt-datalake-nspkg>=2.0.0 (from azure-mgmt-datalake-analytics~=0.6.0->azure-mgmt~=4.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/48/3d/c65a520d93448923a96784582a0deafaae096cb37b444ae5d63b57f0562d/azure_mgmt_datalake_nspkg-3.0.1-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<2.0.0,>=0.4.26->azure-servicefabric~=6.3.0.0->azure)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: azure-keyvault 1.1.0 has requirement cryptography>=2.1.4, but you'll have cryptography 1.2.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: azure-common, azure-storage-common, azure-storage-queue, azure-nspkg, oauthlib, requests-oauthlib, isodate, msrest, azure-servicefabric, adal, msrestazure, azure-batch, azure-eventgrid, azure-cosmosdb-nspkg, azure-cosmosdb-table, azure-applicationinsights, azure-storage-blob, azure-servicemanagement-legacy, azure-servicebus, azure-keyvault, azure-loganalytics, pycparser, cffi, azure-datalake-store, azure-graphrbac, azure-mgmt-nspkg, azure-mgmt-maps, azure-mgmt-notificationhubs, azure-mgmt-compute, azure-mgmt-iothubprovisioningservices, azure-mgmt-containerregistry, azure-mgmt-managementgroups, azure-mgmt-dns, azure-mgmt-marketplaceordering, azure-mgmt-recoveryservicesbackup, azure-mgmt-web, azure-mgmt-media, azure-mgmt-redis, azure-mgmt-advisor, azure-mgmt-msi, azure-mgmt-servicebus, azure-mgmt-datalake-nspkg, azure-mgmt-datalake-analytics, azure-mgmt-devtestlabs, azure-mgmt-resource, azure-mgmt-powerbiembedded, azure-mgmt-machinelearningcompute, azure-mgmt-keyvault, azure-mgmt-devspaces, azure-mgmt-containerservice, azure-mgmt-storage, azure-mgmt-scheduler, azure-mgmt-commerce, azure-mgmt-iothub, azure-mgmt-reservations, azure-mgmt-applicationinsights, azure-mgmt-billing, azure-mgmt-subscription, azure-mgmt-rdbms, azure-mgmt-loganalytics, azure-mgmt-datamigration, azure-mgmt-search, azure-mgmt-batchai, azure-mgmt-trafficmanager, azure-mgmt-datalake-store, azure-mgmt-iotcentral, azure-mgmt-managementpartner, azure-mgmt-hanaonazure, azure-mgmt-cdn, azure-mgmt-datafactory, azure-mgmt-cognitiveservices, azure-mgmt-batch, azure-mgmt-recoveryservices, azure-mgmt-policyinsights, azure-mgmt-containerinstance, azure-mgmt-eventhub, azure-mgmt-servicefabric, azure-mgmt-network, azure-mgmt-logic, azure-mgmt-eventgrid, azure-mgmt-cosmosdb, azure-mgmt-relay, azure-mgmt-authorization, azure-mgmt-signalr, azure-mgmt-monitor, azure-mgmt-sql, azure-mgmt-consumption, azure-mgmt, azure-storage-file, azure\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/azure_common-1.1.23.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import azure\n",
    "    print(\"Azure already installed\")\n",
    "except:\n",
    "    print(\"Installing Azure\")\n",
    "    !pip3 install azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Using Intel® Distribution of OpenVINO™ toolkit\n",
    "\n",
    "We will be using Intel® Distribution of OpenVINO™ toolkit Inference Engine (IE) to locate person in the frame.\n",
    "There are five steps involved in this task:\n",
    "\n",
    "1. Create an Intermediate Representation (IR) Model using the Model Optimizer by Intel\n",
    "2. Choose a device and create IEPlugin for the device\n",
    "3. Read the IRModel using IENetwork\n",
    "4. Load the IENetwork into the Plugin\n",
    "5. Run inference.\n",
    "\n",
    "### 1.1 Creating IR Model\n",
    "\n",
    "The Model Optimizer creates Intermediate Representation (IR) models that are optimized for different end-point target devices.\n",
    "These models can be created from existing DNN models from popular frameworks (e.g. Caffe*, TF) using the Model Optimizer. \n",
    "The Intel® Distribution of OpenVINO™ toolkit includes a utility script `model_downloader.py` that you can use to download some common models. Run the following cell to see the models available through `model_downloader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The '!' is a special Jupyter Notebook command that allows you to run shell commands as if you are in a command line. So the above command will work straight out of the box on in a terminal (with '!' removed).\n",
    "\n",
    "Some of these downloaded models are already in the IR format, while others will require the model optimizer. In this demo, we will be using the **person-detection-retail-0013** model, which is already in IR format. This model can be downloaded with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/FP32/person-detection-retail-0013.xml\n",
      "... 100%, 152 KB, 142 KB/s, 1 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/FP32/person-detection-retail-0013.bin\n",
      "... 100%, 2823 KB, 990 KB/s, 2 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/FP16/person-detection-retail-0013.xml\n",
      "... 100%, 152 KB, 377 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/FP16/person-detection-retail-0013.bin\n",
      "... 100%, 1411 KB, 767 KB/s, 1 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/INT8/person-detection-retail-0013.xml\n",
      "... 100%, 1950 KB, 693 KB/s, 2 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/INT8/person-detection-retail-0013.bin\n",
      "... 100%, 2823 KB, 637 KB/s, 4 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "No matching topologies: \"person-detection-retail-0013-fp16\"\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name person-detection-retail-0013 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name person-detection-retail-0013-fp16 -o models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments are as follows:\n",
    "* --name : name of the model you want to download. It should be one of the models listed in the previous cell\n",
    "* -o : output directory. If this directory does not exist, it will be created for you.\n",
    "\n",
    "There are more arguments to this script and you can get the full list using the `-h` option.\n",
    "\n",
    "\n",
    "With the `-o` option set as above, this command downloads the model in the directory `models`, with the model files (.xml and .bin) located at `/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Inference on a video\n",
    "\n",
    "The inference code is already implemented in \n",
    "<a href=\"main.py\">main.py</a>.\n",
    "\n",
    "The Python code takes in command line arguments for video, model etc.\n",
    "\n",
    "**Command line argument options and how they are interpreted in the application source code**\n",
    "\n",
    "```\n",
    "python3 store_aisle_monitor.py -m ${MODELPATH} \\\n",
    "                -i ${INPUT_FILE} \\\n",
    "                -o ${OUTPUT_FILE} \\\n",
    "                -d ${DEVICE} \\\n",
    "                -pt ${THRESHOLD} \\\n",
    "                -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so\n",
    "```\n",
    "To upload the results to the cloud, the Microsoft Azure storage name and storage key are provided as the command line arguments. Use `-an` and `-ak` options to specify Microsoft Azure storage name and storage key respectively.\n",
    "\n",
    "```\n",
    "python3 store_aisle_monitor.py -m ${MODELPATH} \\\n",
    "                -i ${INPUT_FILE} \\\n",
    "                -o ${OUTPUT_FILE} \\\n",
    "                -d ${DEVICE} \\\n",
    "                -pt ${THRESHOLD} \\\n",
    "                -an <azure-account-name> \\\n",
    "                -ak <azure-account-key> \\\n",
    "                -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so\n",
    "\n",
    "```\n",
    "##### The description of the arguments used in the argument parser is the command line executable equivalent.\n",
    "* -m location of the pre-trained IR model which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware\n",
    "\n",
    "* -i  location of the input video stream\n",
    "* -o location where the output file with inference needs to be stored (results/[device])\n",
    "* -d type of Hardware Acceleration (CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "* -pt probability threshold value for the person detection\n",
    "* -l absolute path to the shared library and is currently optimized for core/xeon (/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so)\n",
    "* -an microsoft azure storage name\n",
    "* -ak microsoft azure storage key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating job file\n",
    " \n",
    "To run inference on the video, we need more compute power.\n",
    "We will run the workload on several edge compute nodes represented in the IoT DevCloud. We will send work to the edge compute nodes by submitting the corresponding non-interactive jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "The job file is written in Bash, and will be executed directly on the edge compute node.\n",
    "For this example, we have written the job file for you in the notebook.\n",
    "Run the following cell to write this in to the file \"store_aisle_job.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"store_aisle_monitor.py\", line 30, in <module>\r\n",
      "    from azure.storage.blob import BlockBlobService, PublicAccess\r\n",
      "ImportError: No module named 'azure'\r\n"
     ]
    }
   ],
   "source": [
    "#Running the store aisle code\n",
    "!python3 store_aisle_monitor.py  -m models/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/FP32/person-detection-retail-0013.xml -i resources/store-aisle-detection.mp4 -o results -d CPU -pt 0.7 -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understand how jobs are submitted into the queue\n",
    "\n",
    "Now that we have the job script, we can submit the jobs to edge compute nodes. In the IoT DevCloud, you can do this using the `qsub` command.\n",
    "We can submit store_aisle_job to several different types of edge compute nodes simultaneously or just one node at a time.\n",
    "\n",
    "There are three options of `qsub` command that we use for this:\n",
    "- `-l` : this option let us select the number and the type of nodes using `nodes={node_count}:{property}`. \n",
    "- `-F` : this option let us send arguments to the bash script. \n",
    "- `-N` : this option let us name the job so that it is easier to distinguish between them.\n",
    "\n",
    "The `-F` flag is used to pass in arguments to the job script.\n",
    "The [store_aisle_job.sh](store_aisle_job.sh) takes in 5 arguments:\n",
    "1. the path to the directory for the output video and performance stats\n",
    "2. targeted device (e.g. CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "3. the floating precision to use for inference\n",
    "4. location of the input video stream\n",
    "5. probability threshold value for the person detection\n",
    "\n",
    "The job scheduler will use the contents of `-F` flag as the argument to the job script.\n",
    "\n",
    "If you are curious to see the available types of nodes on the IoT DevCloud, run the following optional cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pbsnodes | grep compnode | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the properties describe the node, and number on the left is the number of available nodes of that architecture.\n",
    "\n",
    "**Note**: If you want to use your own video, change the environment variable 'VIDEO' in the following cell from \"resources/store-aisle-detection.mp4\" to the full path of your uploaded video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"resources/store-aisle-detection.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Job queue submission\n",
    "\n",
    "Each of the cells below will submit a job to different edge compute nodes.\n",
    "The output of the cell is the `JobID` of your job, which you can use to track progress of a job.\n",
    "\n",
    "**Note** You can submit all jobs at once or follow one at a time. \n",
    "\n",
    "After submission, they will go into a queue and run as soon as the requested compute resources become available. \n",
    "(tip: **shift+enter** will run the cell and automatically move you to the next cell. So you can hit **shift+enter** multiple times to quickly run multiple cells)\n",
    "\n",
    "#### Submitting to an edge compute node with an Intel® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core™ i5-6500TE processor</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_core = !qsub store_aisle_job.sh -l nodes=1:tank-870:i5-6500te -F \"results/core/ CPU FP32 $VIDEO 0.7\" -N store_core\n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/core/', 'i_progress_'+job_id_core[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel® \n",
    "    Xeon® Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_xeon = !qsub store_aisle_job.sh  -l nodes=1:tank-870:e3-1268l-v5 -F \"results/xeon/ CPU FP32 $VIDEO 0.7\" -N store_xeon \n",
    "print(job_id_xeon[0]) \n",
    "#Progress indicators\n",
    "if job_id_xeon:\n",
    "    progressIndicator('results/xeon/', 'i_progress_'+job_id_xeon[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Core CPU and using the onboard Intel® GPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub store_aisle_job.sh -l nodes=1:tank-870:i5-6500te:intel-hd-530 -F \"results/gpu/ GPU FP32 $VIDEO 0.7\" -N store_gpu \n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/gpu/', 'i_progress_'+job_id_gpu[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® NCS 2 (Neural Compute Stick 2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/neural-compute-stick\">Intel Neural Compute Stick 2</a> installed in this  node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub store_aisle_job.sh -l nodes=1:tank-870:i5-6500te:intel-ncs2 -F \"results/ncs2/ MYRIAD FP16 $VIDEO 0.7\" -N store_ncs2\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/ncs2/', 'i_progress_'+job_id_ncs2[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with UP Squared Grove IoT Development Kit (UP2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/up-squared-grove-dev-kit\">UP Squared Grove IoT Development Kit</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/96488/Intel-Atom-x7-E3950-Processor-2M-Cache-up-to-2-00-GHz-\">Intel® Atom® x7-E3950 Processor</a>. The inference  workload will run on the integrated Intel® HD Graphics 505 card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_up2 = !qsub store_aisle_job.sh -l nodes=1:up-squared -F \"results/up2/ GPU FP32 $VIDEO 0.7\" -N store_up2\n",
    "print(job_id_up2[0]) \n",
    "#Progress indicators\n",
    "if job_id_up2:\n",
    "    progressIndicator('results/up2/', 'i_progress_'+job_id_up2[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core™ i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-f100/en/\"> IEI Mustang-F100-A10 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_fpga = !qsub store_aisle_job.sh -l nodes=1:tank-870:i5-6500te:iei-mustang-f100-a10 -F \"results/fpga/ HETERO:FPGA,CPU FP32 $VIDEO 0.7\" -N store_fpga\n",
    "print(job_id_fpga[0]) \n",
    "#Progress indicators\n",
    "if job_id_fpga:\n",
    "    progressIndicator('results/fpga/', 'i_progress_'+job_id_fpga[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check if the jobs are done\n",
    "\n",
    "To check on the jobs that were submitted, use the `qstat` command.\n",
    "\n",
    "We have created a custom Jupyter widget  to get live qstat update.\n",
    "Run the following cell to bring it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs you have submitted (referenced by `Job ID` that gets displayed right after you submit the job in step 2.3).\n",
    "There should also be an extra job in the queue \"jupyterhub\": this job runs your current Jupyter Notebook session.\n",
    "\n",
    "The 'S' column shows the current status. \n",
    "- If it is in Q state, it is in the queue waiting for available resources. \n",
    "- If it is in R state, it is running. \n",
    "- If the job is no longer listed, it means it is completed.\n",
    "\n",
    "**Note**: Time spent in the queue depends on the number of users accessing the edge nodes. Once these jobs begin to run, they should take from 1 to 5 minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Wait!***\n",
    "\n",
    "Please wait for the inference jobs and video rendering to complete before proceeding to the next step.\n",
    "\n",
    "## Step 3: View Results\n",
    "\n",
    "Once the jobs are completed, the queue system outputs the stdout and stderr streams of each job into files with names of the form\n",
    "\n",
    "`store_{type}.o{JobID}`\n",
    "\n",
    "`store_{type}.e{JobID}`\n",
    "\n",
    "(here, store_{type} corresponds to the `-N` option of qsub).\n",
    "\n",
    "However, for this case, we may be more interested in the output video files. They are stored in mp4 format inside the `results/[device]` directory.\n",
    "We wrote a short utility script that will display these videos within the notebook.\n",
    "Run the cells below to display them.\n",
    "See `demoutils.py` if you are interested in understanding further on how the results are displayed in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank (Intel Core CPU)', \n",
    "         ['results/core/store_aisle.mp4'],'results/core/stats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Intel GPU (Intel Core + Onboard GPU)', \n",
    "          ['results/gpu/store_aisle.mp4'],'results/gpu/stats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + Intel CPU + Intel NCS2', \n",
    "          ['results/ncs2/store_aisle.mp4'],'results/ncs2/stats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank Xeon (Intel Xeon CPU)', \n",
    "          ['results/xeon/store_aisle.mp4'],'results/xeon/stats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('UP Squared Grove IoT Development Kit (UP2)', \n",
    "          ['results/up2/store_aisle.mp4'],'results/up2/stats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)', \n",
    "          ['results/fpga/store_aisle.mp4'],'results/fpga/stats.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Assess Performance\n",
    "\n",
    "The running time of each inference task is recorded in `results/[device]/stats.txt`. Run the cell below to plot the results of all jobs side-by-side. Lower values mean better performance for **Inference Engine Processing Time**. Keep in mind that some architectures are optimized for the highest performance, others for low power or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\nE3-1268L v5\\nCPU'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "             ('fpga', 'IEI Mustang\\nF100-A10\\nFPGA'),\n",
    "             ('ncs2', 'Intel\\nNCS2'),\n",
    "             ('up2', 'Intel Atom\\nx7-E3950\\nUP2/GPU')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append(('results/'+arch+'/stats'+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time' )\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
