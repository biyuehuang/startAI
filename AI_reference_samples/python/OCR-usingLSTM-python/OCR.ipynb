{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR (Optical Character Recognition)\n",
    "\n",
    "This is an example for OCR (Optical Character Recognition) using the Intel® Distribution of OpenVINO™ toolkit.  \n",
    "We will use the Convolutional Recurrent Neural Networks (CRNN) for Scene Text Recognition from the following github page : https://github.com/MaybeShewill-CV/CRNN_Tensorflow\n",
    "\n",
    "To obtain the frozen model necessary to start with the Intel® Distribution of OpenVINO™ toolkit from the github repository, please look at our [documentation](https://docs.openvinotoolkit.org/R5/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_CRNN_From_Tensorflow.html) \n",
    "\n",
    "In this tutorial, we will show you first how to convert the TF (TensorFlow) frozen model through the Model Optimizer, then we will perform inference on the CPU (first Intel® Xeon® CPU and then Intel® Core™ CPUs).\n",
    "As the CRNN includes a LSTM (Long Short-term Memory) cell, the inference can only be performed on CPU (the only hardware plugin to support this layer yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup the Python environement \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Optimizer\n",
    "\n",
    "\n",
    "Model Optimizer creates Intermediate Representation (IR) models that are optimized for inference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "--input_model model/crnn.pb \\\n",
    "--data_type FP32 \\\n",
    "-o model/FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** the above line is a single command line input, which spans 4 lines thanks to the backslash '\\\\', which is a line continuation character in Bash.\n",
    "\n",
    "Here, the arguments are:\n",
    "* --input-model : the original model\n",
    "* --data_type : Data type to use. One of {FP32, FP16, half, float}\n",
    "* -o : output directory\n",
    "\n",
    "This script also supports `-h` that will you can get the full list of arguments.\n",
    "\n",
    "With the `-o` option set as above, this command will write the output to the directory `model/FP32`\n",
    "\n",
    "There are two files produced:\n",
    "```\n",
    "models/FP32/crnn.xml\n",
    "models/FP32/crnn.bin\n",
    "```\n",
    "These will be used later in the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference Engine\n",
    "\n",
    "Now, we will run the inference on this model by building progressively the Python sample required to perform inference. \n",
    "This part of exercise feaures our Python API, similar functionalities can be found in our C++ API too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do OCR on the following input image, which obviously reads as **Industries**.\n",
    "![Image](board4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import easydict\n",
    "    print(\"easydict already installed\")\n",
    "except:\n",
    "    print(\"Installing easydict\")\n",
    "    !pip3 install --user easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from local_utils import log_utils, data_utils\n",
    "from local_utils.config_utils import load_config\n",
    "import os.path as ops\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define variables  like model path, target device, the codec for letter conversion\n",
    "You can change the image input_arg here to inference on your own image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xml='model/FP32/crnn.xml'\n",
    "device_arg='CPU'\n",
    "input_arg=['board4.jpg']\n",
    "iterations=1\n",
    "perf_counts=False\n",
    "\n",
    "codec = data_utils.TextFeatureIO(char_dict_path='Config/char_dict.json',ord_map_dict_path=r'Config/ord_map.json')\n",
    "log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plugin initialization for specified device and load extensions library if specified\n",
    "Now we must select the device used for inferencing. This is done by loading the appropriate plugin to initialize the specified device and load the extensions library (if specified) provided in the extension/ folder for the device.\n",
    "\n",
    "The following cell constructs **`IEPlugin`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plugin = IEPlugin(device=device_arg, plugin_dirs='')\n",
    "#print(plugin)\n",
    "\n",
    "# Plugin initialization for specified device. We will be targeting CPU initially.\n",
    "plugin = IEPlugin(device=device_arg)\n",
    "\n",
    "# Loading additional extension libraries for the CPU\n",
    #"plugin.add_cpu_extension('/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read IR\n",
    "We can import optimized models (weights) from step 1 into our neural network using **`IENetwork`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "net = IENetwork(model=model_xml, weights=model_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing input blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "net.batch_size = len(input_arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and pre-process input images\n",
    "First let's load the image using OpenCV.\n",
    "We will also have to do some shape manipulation to convert the image to a format that is compatible with our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "images = np.ndarray(shape=(n, c, h, w))\n",
    "for i in range(n):\n",
    "    image = cv2.imread(input_arg[i])\n",
    "    if image.shape[:-1] != (h, w):\n",
    "        log.warning(\"Image {} is resized from {} to {}\".format(input_arg[i], image.shape[:-1], (h, w)))\n",
    "        image = cv2.resize(image, (w, h))\n",
    "    image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "    images[i] = image\n",
    "log.info(\"Batch size is {}\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading model to the plugin\n",
    "Once we have the plugin and the network, we can load the network into the plugin using **`plugin.load`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_net = plugin.load(network=net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Inference\n",
    "We can now run the inference on the object  **`exec_net`** using the function infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_time = []\n",
    "for i in range(iterations):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time()-t0)*1000)\n",
    "\n",
    "res = res[out_blob]\n",
    "    \n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing output blob\n",
    "The network outputs a tensor of dimension 25 (string length) * 37 (dimension of character space).\n",
    "First, we will go through the 25 characters and extracts the highest probability in the character space and its index in this space. \n",
    "We use the encoding files from the Github page to recover the mapping from index to character. (0&rarr;\"a\",36&rarr;\" \")\n",
    "In the github page, they also remove the consecutive duplicates and the space char, therefore we also perform this postprocessing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = res.argmax(2) ## extract highest probability in the second dimension\n",
    "preds = preds.transpose(1, 0)\n",
    "preds = np.ascontiguousarray(preds, dtype=np.int8).view(dtype=np.int8) # reformat to an array \n",
    "values=codec.writer.ordtochar( preds[0].tolist()) # map from index to character\n",
    "values=[v for i, v in enumerate(values) if i == 0 or v != values[i-1]] # remove duplicates\n",
    "values = [x for x in values if x != ' '] # remove space char (was character from index 36)\n",
    "res=''.join(values)\n",
    "print(\"The result is : \" + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
